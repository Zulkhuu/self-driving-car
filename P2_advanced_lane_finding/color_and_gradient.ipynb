{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "#from camera_calibration import read_calibration, undistort_image\n",
    "#from color_and_gradient import pipeline\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML, display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_imlist(images, fig_size=(30,15)):\n",
    "    \"Plot images horizontally\"\n",
    "    plt.figure()\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    fig, axs = plt.subplots(1, len(images))\n",
    "    for i in range(len(images)):\n",
    "        if len(images[i].shape) == 2:\n",
    "            # Binary image\n",
    "            axs[i].imshow(np.dstack((images[i], images[i], images[i]))*255)\n",
    "        else:\n",
    "            axs[i].imshow(images[i])\n",
    "    \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    # Convert to HLS color space and separate the S channel\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Apply Sobel filter in horizontal direction\n",
    "    sobelx = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient magnitude\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "\n",
    "    # Threshold Saturation channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    # Stack each channel\n",
    "    ret = np.zeros_like(s_channel)\n",
    "    ret[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob(\"test_images/**.jpg\")\n",
    "\n",
    "def tuning_on_image(img_idx, sat_thresh, sobel_thresh):\n",
    "    img = mpimg.imread(images[img_idx])\n",
    "    processed_img = pipeline(img, s_thresh=(sat_thresh[0], sat_thresh[1]), sx_thresh=(sobel_thresh[0], sobel_thresh[1]))\n",
    "    plt_imlist([img, processed_img]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec1c50d0e854773b01650ece755690b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='img_idx', max=7, min=1), IntRangeSlider(value=(170, 255)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interactive(tuning_on_image,\n",
    "                    img_idx=widgets.IntSlider(min=1, max=len(images)-1, step=1, value=1),  \n",
    "                    sat_thresh=widgets.IntRangeSlider(min=0, max=255, step=1,value=[170, 255]),\n",
    "                    sobel_thresh=widgets.IntRangeSlider(min=0, max=255, step=1,value=[20, 100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on challenge video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = VideoFileClip('test_videos/harder_challenge_video.mp4')\n",
    "\n",
    "def tuning_on_video(frame_idx, sat_thresh, sobel_thresh):\n",
    "    img = video.get_frame(frame_idx)\n",
    "    processed_img = pipeline(img, s_thresh=(sat_thresh[0], sat_thresh[1]), sx_thresh=(sobel_thresh[0], sobel_thresh[1]))\n",
    "    plt_imlist([img, processed_img]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40709b9cfd1e40e5b558aa194c6f3978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame_idx', max=1198, min=1), IntRangeSlider(value=(170,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interactive(tuning_on_video,\n",
    "                    frame_idx=widgets.IntSlider(min=1, max=video.reader.nframes-1, step=1, value=1),  \n",
    "                    sat_thresh=widgets.IntRangeSlider(min=0, max=255, step=1,value=[170, 255]),\n",
    "                    sobel_thresh=widgets.IntRangeSlider(min=0, max=255, step=1,value=[20, 100]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
